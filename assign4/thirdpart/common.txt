
1. What are the assumptions of linear regression?

Linear regression assumes the following:
i)Linearity: Relationship between independent and dependent variables is linear.

ii)Independence: Observations are independent of each other.

iii)Homoscedasticity: Constant variance of residuals across all levels of independent variables.

iv)Normality of Errors: Residuals (errors) are normally distributed.

v)No Multicollinearity: Independent variables are not highly correlated with each other.


2. When should you use logistic regression instead of linear regression?

Use logistic regression when:

i)The dependent variable is categorical, especially binary (e.g., 0/1, yes/no).

ii)You want to model probabilities of class membership.

iii)The output must be between 0 and 1 (as a probability), which linear regression cannot guarantee.


3. What is the interpretation of coefficients in logistic regression?

The coefficient shows how much the odds change when a feature increases.
If you increase a feature by 1, the chance of outcome (like getting 1) goes up or down.


4. What is the difference between sigmoid and softmax functions?
Sigmoid: Used for two-class problems (gives one value between 0 and 1).
Softmax: Used for multi-class problems (gives a set of probabilities that add to 1)


5. Why is R-squared not suitable for evaluating logistic regression models?
R-squared is not suitable because:

It's based on the sum of squared errors, which assumes a continuous dependent variable.

Logistic regression predicts probabilities for categorical outcomes, not continuous values.
Instead, use metrics suited for classification, like:
Accuracy
Precision, Recall, F1-score
AUC-ROC
Log Loss
